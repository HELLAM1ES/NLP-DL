{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5hzk-0zh25JX",
   "metadata": {
    "id": "5hzk-0zh25JX"
   },
   "source": [
    "# Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# Pour BERT\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zWgSP3bIAg6H",
   "metadata": {
    "id": "zWgSP3bIAg6H"
   },
   "source": [
    "### Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4U_Sm-gVAl-j",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/clean_dataset.csv\")\n",
    "df = df.dropna(subset=['text_processed'])\n",
    "df = df[df['text_processed'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_CTeuQQOA1B-",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text_processed']\n",
    "y = df['humor']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68iEzrbaA4y4",
   "metadata": {
    "id": "68iEzrbaA4y4"
   },
   "source": [
    "### Vectoriseurs et Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laknAEEiA5PR",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    \"tfidf\": TfidfVectorizer(max_features=5000),\n",
    "    \"count\": CountVectorizer(max_features=5000)\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"NaiveBayes\": MultinomialNB(),\n",
    "    \"SVM\": LinearSVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ELsH2wiHBC_S",
   "metadata": {
    "id": "ELsH2wiHBC_S"
   },
   "source": [
    "### Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fJFs2kt1BDY0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for vec_name, vectorizer in tqdm(vectorizers.items(), desc=\"Vectorisations\"):\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    for model_name, model in tqdm(models.items(), desc=f\"Modèles ({vec_name})\", leave=False):\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        results.append({\n",
    "            \"Vectorizer\": vec_name,\n",
    "            \"Model\": model_name,\n",
    "            \"F1 (macro)\": round(report['macro avg']['f1-score'], 4),\n",
    "            \"Accuracy\": round(report['accuracy'], 4)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\" Résultats des modèles classiques :\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e067190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\" Device utilisé :\", device)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# échantillon de 5000 exemples\n",
    "sample_df = pd.concat([X_train, y_train], axis=1).sample(5000, random_state=42)\n",
    "X_sample = sample_df['text_processed']\n",
    "y_sample = sample_df['humor']\n",
    "\n",
    "# Dataset\n",
    "class HumorDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(labels.tolist(), dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Création des datasets et loaders\n",
    "train_dataset = HumorDataset(X_sample, y_sample, tokenizer)\n",
    "test_dataset = HumorDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Modèle BERT\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Optimiseur\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Entraînement\n",
    "model.train()\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(train_loader, desc=f\" Epoch {epoch+1}\")\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Évaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\" Évaluation\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "print(\" Rapport de classification — BERT (échantillon 5000)\")\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434dff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q transformers datasets scikit-learn pandas seaborn matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, get_scheduler\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Chargement des données\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df['label'] = df['humor'].astype(int)\n",
    "df_sampled = df.sample(frac=0.05, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_df, val_df, test_df = np.split(df_sampled.sample(frac=1, random_state=42), [int(.8*len(df_sampled)), int(.9*len(df_sampled))])\n",
    "train_df = train_df.rename(columns={'label': 'labels'})\n",
    "test_df = test_df.rename(columns={'label': 'labels'})\n",
    "\n",
    "# Tokenisation\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "def tokenize(example): return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=50)\n",
    "train_ds = HFDataset.from_pandas(train_df[['text', 'labels']]).map(tokenize, batched=True)\n",
    "test_ds = HFDataset.from_pandas(test_df[['text', 'labels']]).map(tokenize, batched=True)\n",
    "train_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Modèle\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Entraînement\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*3)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss = model(**batch).loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Évaluation\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "model.eval(); preds, labels = [], []\n",
    "for batch in tqdm(test_loader, desc=\"Evaluation\"):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad(): out = model(**batch).logits\n",
    "    preds.extend(torch.argmax(out, dim=-1).cpu().numpy())\n",
    "    labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "print(f\"\\n F1 score on test set: {f1_score(labels, preds):.4f}\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-humor\", \"Humor\"], yticklabels=[\"Non-humor\", \"Humor\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(labels, preds)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc(fpr, tpr):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# PR Curve\n",
    "precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label=\"Precision-Recall curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"PR Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(labels, preds))\n",
    "\n",
    "# Erreurs typiques\n",
    "errors = [(i, l, p) for i, (l, p) in enumerate(zip(labels, preds)) if l != p]\n",
    "for idx, true, pred in errors[:5]:\n",
    "    text = test_df.iloc[idx]['text']\n",
    "    print(f\"\\n Mal classé : {text}\")\n",
    "    print(f\" Vrai label : {true} |  Prédit : {pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
